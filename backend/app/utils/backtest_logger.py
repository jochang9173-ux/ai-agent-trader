"""
Backtest Logger
Records detailed decision processes and analysis data for LLM strategies
"""

import json
import sqlite3
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import pandas as pd


class BacktestLogger:
    """
    Backtest Logger

    Records detailed decision processes for LLM strategies, including:
    - Daily market analysis
    - Triggered events
    - LLM decision processes
    - Trading signals
    - Strategy states
    """

    def __init__(
        self, db_path: str = "backend/data/backtest_logs.db", session_id: str = None
    ):
        """
        Initialize the logger

        Args:
            db_path: SQLite database file path
            session_id: Backtest session ID, auto-generated if not provided
        """
        self.db_path = Path(db_path)
        # Ensure parent directory exists
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.session_id = session_id or str(uuid.uuid4())
        self._init_database()

    def _init_database(self):
        """ÂàùÂßãÂåñÊï∏ÊìöÂ∫´ÁµêÊßã"""
        with sqlite3.connect(self.db_path) as conn:
            # ÂâµÂª∫‰∏ªË°®ÔºöÊØèÊó•ÂàÜÊûêÊó•Ë™å
            conn.execute("""
                CREATE TABLE IF NOT EXISTS daily_analysis_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    symbol TEXT NOT NULL,
                    date DATE NOT NULL,
                    timestamp DATETIME NOT NULL,
                    
                    -- Âü∫Êú¨Â∏ÇÂ†¥Êï∏Êìö (ÁµêÊßãÂåñÔºå‰æøÊñºÊü•Ë©¢)
                    price REAL,
                    volume INTEGER,
                    daily_return REAL,
                    volatility REAL,
                    
                    -- Ë∂®Âã¢ÂàÜÊûê (JSON)
                    trend_analysis TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- ÂÖ®Èù¢ÊäÄË°ìÂàÜÊûê (JSON) - Êñ∞Â¢û
                    comprehensive_technical_analysis TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- Ëß∏Áôº‰∫ã‰ª∂ (JSON)
                    triggered_events TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- LLMÊ±∫Á≠ñ (JSON)
                    llm_decision TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- ‰∫§Êòì‰ø°Ëôü (JSON)
                    trading_signal TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- Á≠ñÁï•ÁãÄÊÖã (JSON)
                    strategy_state TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- ÁµêÊûúË©ï‰º∞ (ÂæåÁ∫åÊõ¥Êñ∞)
                    actual_pnl REAL,
                    prediction_accuracy REAL,
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # ÂâµÂª∫‰∫ã‰ª∂ÂàÜÊûêË°®
            conn.execute("""
                CREATE TABLE IF NOT EXISTS event_analysis_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    daily_log_id INTEGER,
                    event_type TEXT NOT NULL,
                    severity TEXT,
                    detection_time DATETIME,
                    
                    -- Â∏ÇÂ†¥‰∏ä‰∏ãÊñá (JSON)
                    market_context TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- LLMÈüøÊáâ (JSON) 
                    llm_response TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    -- ÊïàÊûúË©ï‰º∞ (JSON)
                    effectiveness TEXT, -- JSONÂ≠óÁ¨¶‰∏≤
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    FOREIGN KEY (daily_log_id) REFERENCES daily_analysis_logs (id)
                )
            """)

            # ÂâµÂª∫Á¥¢Âºï
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_daily_logs_date_symbol 
                ON daily_analysis_logs (date, symbol)
            """)

            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_daily_logs_session 
                ON daily_analysis_logs (session_id)
            """)

            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_events_type 
                ON event_analysis_logs (event_type)
            """)

            conn.commit()

    def log_daily_analysis(
        self,
        symbol: str,
        date: str,
        market_data: Dict[str, Any],
        trend_analysis: Dict[str, Any] = None,
        comprehensive_technical_analysis: Dict[str, Any] = None,  # Êñ∞Â¢ûÂèÉÊï∏
        triggered_events: List[Dict[str, Any]] = None,
        llm_decision: Dict[str, Any] = None,
        trading_signal: Dict[str, Any] = None,
        strategy_state: Dict[str, Any] = None,
    ) -> int:
        """
        Ë®òÈåÑÊØèÊó•ÂàÜÊûêÊï∏Êìö (Êñ∞Ë®òÈåÑÊúÉË¶ÜËìãÂêå‰∏ÄËÇ°Á•®Âêå‰∏ÄÂ§©ÁöÑËàäË®òÈåÑ)

        Args:
            symbol: ËÇ°Á•®‰ª£Á¢º
            date: Êó•Êúü (YYYY-MM-DD)
            market_data: Â∏ÇÂ†¥Êï∏ÊìöÂ≠óÂÖ∏
            trend_analysis: Ë∂®Âã¢ÂàÜÊûêÁµêÊûú
            comprehensive_technical_analysis: ÂÖ®Èù¢ÊäÄË°ìÂàÜÊûêÁµêÊûú
            triggered_events: Ëß∏Áôº‰∫ã‰ª∂ÂàóË°®
            llm_decision: LLMÊ±∫Á≠ñÁµêÊûú
            trading_signal: ‰∫§Êòì‰ø°Ëôü
            strategy_state: Á≠ñÁï•ÁãÄÊÖã

        Returns:
            Ë®òÈåÑÁöÑID
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # Ê™¢Êü•ÊòØÂê¶Â≠òÂú®Áõ∏ÂêåÁöÑË®òÈåÑ (Âêå‰∏Äsymbol + date)
            cursor.execute(
                """
                SELECT id FROM daily_analysis_logs 
                WHERE symbol = ? AND date = ?
                ORDER BY timestamp DESC
            """,
                (symbol, date),
            )

            existing_records = cursor.fetchall()

            if existing_records:
                # Âà™Èô§ËàäË®òÈåÑÂíåÁõ∏ÈóúÁöÑ‰∫ã‰ª∂Ë®òÈåÑ
                old_ids = [record[0] for record in existing_records]
                old_ids_str = ",".join("?" * len(old_ids))

                # ÂÖàÂà™Èô§Áõ∏ÈóúÁöÑ‰∫ã‰ª∂ÂàÜÊûêË®òÈåÑ
                cursor.execute(
                    f"""
                    DELETE FROM event_analysis_logs 
                    WHERE daily_log_id IN ({old_ids_str})
                """,
                    old_ids,
                )

                # ÂÜçÂà™Èô§ÊØèÊó•ÂàÜÊûêË®òÈåÑ
                cursor.execute(
                    f"""
                    DELETE FROM daily_analysis_logs 
                    WHERE id IN ({old_ids_str})
                """,
                    old_ids,
                )

                print(f"üîÑ Ë¶ÜËìã {symbol} - {date} ÁöÑËàäË®òÈåÑ ({len(old_ids)}Ê¢ù)")

            # ÊèíÂÖ•Êñ∞Ë®òÈåÑ
            cursor.execute(
                """
                INSERT INTO daily_analysis_logs (
                    session_id, symbol, date, timestamp,
                    price, volume, daily_return, volatility,
                    trend_analysis, comprehensive_technical_analysis, triggered_events, llm_decision,
                    trading_signal, strategy_state
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    self.session_id,
                    symbol,
                    date,
                    datetime.now().isoformat(),
                    market_data.get("price"),
                    market_data.get("volume"),
                    market_data.get("daily_return"),
                    market_data.get("volatility"),
                    json.dumps(trend_analysis) if trend_analysis else None,
                    json.dumps(comprehensive_technical_analysis)
                    if comprehensive_technical_analysis
                    else None,
                    json.dumps(triggered_events) if triggered_events else None,
                    json.dumps(llm_decision) if llm_decision else None,
                    json.dumps(trading_signal) if trading_signal else None,
                    json.dumps(strategy_state) if strategy_state else None,
                ),
            )

            return cursor.lastrowid

    def log_event_analysis(
        self,
        daily_log_id: int,
        event_type: str,
        severity: str,
        market_context: Dict[str, Any] = None,
        llm_response: Dict[str, Any] = None,
        effectiveness: Dict[str, Any] = None,
    ):
        """
        Ë®òÈåÑ‰∫ã‰ª∂ÂàÜÊûêÊï∏Êìö

        Args:
            daily_log_id: Â∞çÊáâÁöÑÊó•Ë™åË®òÈåÑID
            event_type: ‰∫ã‰ª∂È°ûÂûã
            severity: Âö¥ÈáçÁ®ãÂ∫¶
            market_context: Â∏ÇÂ†¥‰∏ä‰∏ãÊñá
            llm_response: LLMÈüøÊáâ
            effectiveness: ÊïàÊûúË©ï‰º∞
        """
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                INSERT INTO event_analysis_logs (
                    session_id, daily_log_id, event_type, severity,
                    detection_time, market_context, llm_response, effectiveness
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    self.session_id,
                    daily_log_id,
                    event_type,
                    severity,
                    datetime.now().isoformat(),
                    json.dumps(market_context) if market_context else None,
                    json.dumps(llm_response) if llm_response else None,
                    json.dumps(effectiveness) if effectiveness else None,
                ),
            )

    def update_actual_results(
        self, log_id: int, actual_pnl: float, prediction_accuracy: float
    ):
        """
        Êõ¥Êñ∞ÂØ¶ÈöõÁµêÊûú

        Args:
            log_id: Êó•Ë™åË®òÈåÑID
            actual_pnl: ÂØ¶ÈöõÊêçÁõä
            prediction_accuracy: È†êÊ∏¨Ê∫ñÁ¢∫Â∫¶
        """
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                UPDATE daily_analysis_logs 
                SET actual_pnl = ?, prediction_accuracy = ?
                WHERE id = ?
            """,
                (actual_pnl, prediction_accuracy, log_id),
            )

    def query_logs(
        self,
        symbol: str = None,
        date_from: str = None,
        date_to: str = None,
        event_type: str = None,
        limit: int = 100,
    ) -> List[Dict[str, Any]]:
        """
        Êü•Ë©¢Êó•Ë™åË®òÈåÑ

        Args:
            symbol: ËÇ°Á•®‰ª£Á¢º
            date_from: ÈñãÂßãÊó•Êúü
            date_to: ÁµêÊùüÊó•Êúü
            event_type: ‰∫ã‰ª∂È°ûÂûã
            limit: ÈôêÂà∂ËøîÂõûÊï∏Èáè

        Returns:
            Êó•Ë™åË®òÈåÑÂàóË°®
        """
        query = """
            SELECT d.*, GROUP_CONCAT(e.event_type) as event_types
            FROM daily_analysis_logs d
            LEFT JOIN event_analysis_logs e ON d.id = e.daily_log_id
            WHERE d.session_id = ?
        """
        params = [self.session_id]

        if symbol:
            query += " AND d.symbol = ?"
            params.append(symbol)

        if date_from:
            query += " AND d.date >= ?"
            params.append(date_from)

        if date_to:
            query += " AND d.date <= ?"
            params.append(date_to)

        query += " GROUP BY d.id ORDER BY d.date DESC, d.timestamp DESC"

        if limit:
            query += f" LIMIT {limit}"

        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute(query, params)
            rows = cursor.fetchall()

            # ËΩâÊèõÁÇ∫Â≠óÂÖ∏‰∏¶Ëß£ÊûêJSONÂ≠óÊÆµ
            results = []
            for row in rows:
                record = dict(row)

                # Ëß£ÊûêJSONÂ≠óÊÆµ
                for json_field in [
                    "trend_analysis",
                    "comprehensive_technical_analysis",
                    "triggered_events",
                    "llm_decision",
                    "trading_signal",
                    "strategy_state",
                ]:
                    if record[json_field]:
                        try:
                            record[json_field] = json.loads(record[json_field])
                        except json.JSONDecodeError:
                            record[json_field] = None

                results.append(record)

            return results

    def get_session_summary(self) -> Dict[str, Any]:
        """
        Áç≤ÂèñÊúÉË©±ÊëòË¶ÅÁµ±Ë®à

        Returns:
            ÊúÉË©±Áµ±Ë®àÊï∏Êìö
        """
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row  # ÂïüÁî®RowÂ∑•Âª†

            # Âü∫Êú¨Áµ±Ë®à
            cursor = conn.execute(
                """
                SELECT 
                    COUNT(*) as total_days,
                    COUNT(DISTINCT symbol) as symbols_count,
                    MIN(date) as start_date,
                    MAX(date) as end_date,
                    AVG(actual_pnl) as avg_pnl,
                    SUM(actual_pnl) as total_pnl
                FROM daily_analysis_logs 
                WHERE session_id = ?
            """,
                (self.session_id,),
            )

            row = cursor.fetchone()
            basic_stats = dict(row) if row else {}

            # LLMÊ±∫Á≠ñÁµ±Ë®à
            cursor = conn.execute(
                """
                SELECT 
                    COUNT(*) as total_decisions,
                    AVG(CASE WHEN json_extract(llm_decision, '$.decision_made') = 1 
                        THEN 1 ELSE 0 END) as decision_rate,
                    AVG(CAST(json_extract(llm_decision, '$.confidence') AS REAL)) as avg_confidence
                FROM daily_analysis_logs 
                WHERE session_id = ? AND llm_decision IS NOT NULL
            """,
                (self.session_id,),
            )

            row = cursor.fetchone()
            llm_stats = dict(row) if row else {}

            # ‰∫ã‰ª∂Áµ±Ë®à
            cursor = conn.execute(
                """
                SELECT 
                    event_type,
                    COUNT(*) as count,
                    AVG(CASE WHEN severity = 'high' THEN 1 ELSE 0 END) as high_severity_rate
                FROM event_analysis_logs 
                WHERE session_id = ?
                GROUP BY event_type
                ORDER BY count DESC
            """,
                (self.session_id,),
            )

            event_stats = [dict(row) for row in cursor.fetchall()]

            return {
                "session_id": self.session_id,
                "basic_stats": basic_stats,
                "llm_stats": llm_stats,
                "event_stats": event_stats,
            }

    def export_to_json(self, filepath: str):
        """
        Â∞éÂá∫Êó•Ë™åÂà∞JSONÊñá‰ª∂

        Args:
            filepath: Ëº∏Âá∫Êñá‰ª∂Ë∑ØÂæë
        """
        logs = self.query_logs(limit=None)
        summary = self.get_session_summary()

        export_data = {"session_summary": summary, "logs": logs}

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)

        print(f"‚úÖ Êó•Ë™åÂ∑≤Â∞éÂá∫Âà∞: {filepath}")
